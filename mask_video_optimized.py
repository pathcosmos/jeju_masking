#!/usr/bin/env python3
"""
ìµœì í™”ëœ ì–¼êµ´ ë° ë²ˆí˜¸íŒ ë§ˆìŠ¤í‚¹ ìŠ¤í¬ë¦½íŠ¸ v2.4
- ì‹œìŠ¤í…œ í•˜ë“œì›¨ì–´ ìë™ ê°ì§€ ë° ìµœì í™” (CPU/RAM/GPU)
- NVIDIA CUDA GPU ê°€ì† ìµœì í™” (FP16, TensorRT ì§€ì›)
- OpenCV DNN CUDA ê°€ì† (ì–¼êµ´ ê°ì§€ GPU ì²˜ë¦¬)
- MPS GPU ê°€ì† (Apple Silicon)
- ë©€í‹°ìŠ¤ë ˆë”© íŒŒì´í”„ë¼ì¸ (CPU ìŠ¤ë ˆë“œ ê¸°ë°˜ ì›Œì»¤ ìˆ˜ ìë™ ì¡°ì •)
- RAM ê¸°ë°˜ í”„ë ˆì„ í í¬ê¸° ìë™ ì¡°ì •
- GPU VRAM ê¸°ë°˜ ë°°ì¹˜ í¬ê¸° ìë™ ê³„ì‚°
- í”„ë ˆì„ ìŠ¤í‚µ + íŠ¸ë˜í‚¹ ë³´ê°„
- í•´ìƒë„ ë‹¤ìš´ìŠ¤ì¼€ì¼ ê°ì§€ (ì¶œë ¥ì€ ì›ë³¸ ìœ ì§€)
- GPU ë©”ëª¨ë¦¬ ìµœì í™” (cuDNN benchmark, TF32, ìºì‹œ ì •ë¦¬)
- NVENC í•˜ë“œì›¨ì–´ ì¸ì½”ë”© ì§€ì› (RTX ì‹œë¦¬ì¦ˆ)
"""

import argparse
import os
import sys
import logging
from pathlib import Path
from datetime import datetime
from collections import deque
from threading import Thread, Event
from queue import Queue, Empty
import cv2
import numpy as np
from ultralytics import YOLO
import urllib.request
import time
import platform
import yaml
import tempfile


class FlushStreamHandler(logging.StreamHandler):
    """ì¦‰ì‹œ flushë˜ëŠ” ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬"""
    def emit(self, record):
        super().emit(record)
        self.flush()


def setup_logger(log_file=None, verbose=False):
    """ë¡œê±° ì„¤ì • (ì‹¤ì‹œê°„ ì¶œë ¥)"""
    log_format = '%(asctime)s [%(levelname)s] %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'

    # ì‹¤ì‹œê°„ ì¶œë ¥ì„ ìœ„í•œ ì»¤ìŠ¤í…€ í•¸ë“¤ëŸ¬
    console_handler = FlushStreamHandler(sys.stdout)
    console_handler.setFormatter(logging.Formatter(log_format, date_format))
    console_handler.setLevel(logging.DEBUG if verbose else logging.INFO)

    handlers = [console_handler]

    if log_file:
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setFormatter(logging.Formatter(log_format, date_format))
        file_handler.setLevel(logging.DEBUG)
        handlers.append(file_handler)

    logging.basicConfig(level=logging.DEBUG, handlers=handlers, force=True)
    return logging.getLogger(__name__)


# ëª¨ë¸ ê²½ë¡œ
MODELS_DIR = Path(__file__).parent / "models"

# OpenCV DNN ì–¼êµ´ ê°ì§€ ëª¨ë¸
FACE_PROTO_URL = "https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt"
FACE_MODEL_URL = "https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"


def get_system_info():
    """ì‹œìŠ¤í…œ í•˜ë“œì›¨ì–´ ì •ë³´ ìˆ˜ì§‘"""
    import subprocess
    import re
    
    info = {
        'cpu': {},
        'ram': {},
        'gpu': None
    }
    
    # CPU ì •ë³´
    try:
        result = subprocess.run(['lscpu'], capture_output=True, text=True)
        lscpu_output = result.stdout
        
        # ëª¨ë¸ëª…
        model_match = re.search(r'Model name:\s*(.+)', lscpu_output)
        info['cpu']['model'] = model_match.group(1).strip() if model_match else 'Unknown'
        
        # ì½”ì–´ ìˆ˜
        cores_match = re.search(r'Core\(s\) per socket:\s*(\d+)', lscpu_output)
        sockets_match = re.search(r'Socket\(s\):\s*(\d+)', lscpu_output)
        cores = int(cores_match.group(1)) if cores_match else 1
        sockets = int(sockets_match.group(1)) if sockets_match else 1
        info['cpu']['cores'] = cores * sockets
        
        # ìŠ¤ë ˆë“œ ìˆ˜
        threads_match = re.search(r'CPU\(s\):\s*(\d+)', lscpu_output)
        info['cpu']['threads'] = int(threads_match.group(1)) if threads_match else info['cpu']['cores']
        
        # ìµœëŒ€ í´ëŸ­
        max_mhz_match = re.search(r'CPU max MHz:\s*([\d.]+)', lscpu_output)
        info['cpu']['max_mhz'] = float(max_mhz_match.group(1)) if max_mhz_match else 0
        
    except Exception:
        info['cpu'] = {'model': 'Unknown', 'cores': 4, 'threads': 8, 'max_mhz': 0}
    
    # RAM ì •ë³´
    try:
        with open('/proc/meminfo', 'r') as f:
            meminfo = f.read()
        total_match = re.search(r'MemTotal:\s*(\d+)', meminfo)
        available_match = re.search(r'MemAvailable:\s*(\d+)', meminfo)
        
        info['ram']['total_gb'] = int(total_match.group(1)) / (1024**2) if total_match else 0
        info['ram']['available_gb'] = int(available_match.group(1)) / (1024**2) if available_match else 0
    except Exception:
        info['ram'] = {'total_gb': 8, 'available_gb': 4}
    
    # GPU ì •ë³´ (NVIDIA)
    try:
        import torch
        if torch.cuda.is_available():
            props = torch.cuda.get_device_properties(0)
            info['gpu'] = {
                'name': props.name,
                'vram_gb': props.total_memory / (1024**3),
                'compute_capability': f"{props.major}.{props.minor}",
                'multi_processor_count': props.multi_processor_count,
                'type': 'cuda'
            }
    except Exception:
        pass
    
    # MPS ì •ë³´ (Apple Silicon)
    if info['gpu'] is None:
        try:
            import torch
            if torch.backends.mps.is_available() and platform.processor() == 'arm':
                info['gpu'] = {
                    'name': 'Apple Silicon (MPS)',
                    'vram_gb': info['ram']['total_gb'] * 0.75,  # í†µí•© ë©”ëª¨ë¦¬
                    'type': 'mps'
                }
        except Exception:
            pass
    
    return info


def get_optimal_settings(system_info, frame_width=3840, frame_height=2160):
    """ì‹œìŠ¤í…œ ì‚¬ì–‘ì— ë§ëŠ” ìµœì  ì„¤ì • ìë™ ê³„ì‚°"""
    settings = {
        'device': 'cpu',
        'batch_size': 2,
        'detect_scale': 0.5,
        'detect_interval': 3,
        'num_workers': 2,
        'queue_size': 64,
        'use_fp16': False,
    }
    
    cpu = system_info.get('cpu', {})
    ram = system_info.get('ram', {})
    gpu = system_info.get('gpu')
    
    # CPU ìŠ¤ë ˆë“œ ê¸°ë°˜ ì›Œì»¤ ìˆ˜ ì„¤ì • (I/O ë°”ìš´ë“œ ì‘ì—…ì´ë¯€ë¡œ ë” ë§ì€ ì›Œì»¤ í—ˆìš©)
    threads = cpu.get('threads', 8)
    settings['num_workers'] = max(2, min(threads // 2, 12))  # 2~12 ì‚¬ì´ (ìŠ¤ë ˆë“œì˜ ì ˆë°˜)
    
    # RAM ê¸°ë°˜ í í¬ê¸° ì„¤ì •
    ram_gb = ram.get('available_gb', 8)
    if ram_gb >= 24:
        settings['queue_size'] = 256
    elif ram_gb >= 16:
        settings['queue_size'] = 192
    elif ram_gb >= 8:
        settings['queue_size'] = 128
    else:
        settings['queue_size'] = 64
    
    # GPU ì„¤ì •
    if gpu:
        settings['device'] = gpu.get('type', 'cpu')
        vram_gb = gpu.get('vram_gb', 4)
        
        # VRAM ê¸°ë°˜ ë°°ì¹˜ í¬ê¸° ê³„ì‚° (RTX ì‹œë¦¬ì¦ˆ ìµœì í™”)
        # 4K 0.5 scale ê¸°ì¤€ í”„ë ˆì„ë‹¹ ì•½ 50MB, YOLO ëª¨ë¸ ì•½ 500MB
        scaled_pixels = (frame_width * 0.5) * (frame_height * 0.5)
        frame_memory_gb = (scaled_pixels * 3 * 4) / (1024**3)  # float32

        # VRAMì˜ 70% ì‚¬ìš© (ë” ì ê·¹ì ìœ¼ë¡œ GPU í™œìš©)
        available_vram = vram_gb * 0.7 - 0.5  # 0.5GB ëª¨ë¸ìš©
        settings['batch_size'] = max(2, min(int(available_vram / (frame_memory_gb * 2.5)), 24))
        
        # CUDA 8.0+ (Ampere ì´ìƒ)ì—ì„œ FP16 ê¶Œì¥
        compute_cap = gpu.get('compute_capability', '0.0')
        major_version = int(compute_cap.split('.')[0])
        if major_version >= 7 and gpu.get('type') == 'cuda':
            settings['use_fp16'] = True
        
        # ê³ ì„±ëŠ¥ GPU (VRAM ê¸°ë°˜ ì„¤ì • ìµœì í™”)
        if vram_gb >= 12:
            settings['detect_scale'] = 0.6
            settings['detect_interval'] = 1  # ê³ ì„±ëŠ¥ GPUëŠ” ë§¤ í”„ë ˆì„ ê°ì§€ ê°€ëŠ¥
        elif vram_gb >= 8:
            settings['detect_scale'] = 0.5
            settings['detect_interval'] = 2
        elif vram_gb >= 6:
            settings['detect_scale'] = 0.5
            settings['detect_interval'] = 3
        else:
            settings['detect_scale'] = 0.4
            settings['detect_interval'] = 4
    
    return settings


def print_system_info(system_info, settings=None):
    """ì‹œìŠ¤í…œ ì •ë³´ ë° ìµœì  ì„¤ì • ì¶œë ¥"""
    cpu = system_info.get('cpu', {})
    ram = system_info.get('ram', {})
    gpu = system_info.get('gpu')
    
    print("\n" + "=" * 60)
    print("ğŸ–¥ï¸  ì‹œìŠ¤í…œ í•˜ë“œì›¨ì–´ ì •ë³´")
    print("=" * 60)
    
    # CPU
    print(f"\nğŸ’» CPU: {cpu.get('model', 'Unknown')}")
    print(f"   ì½”ì–´: {cpu.get('cores', '?')}ê°œ | ìŠ¤ë ˆë“œ: {cpu.get('threads', '?')}ê°œ")
    if cpu.get('max_mhz'):
        print(f"   ìµœëŒ€ í´ëŸ­: {cpu.get('max_mhz')/1000:.2f} GHz")
    
    # RAM
    print(f"\nğŸ§  RAM: {ram.get('total_gb', 0):.1f} GB (ì‚¬ìš© ê°€ëŠ¥: {ram.get('available_gb', 0):.1f} GB)")
    
    # GPU
    if gpu:
        print(f"\nğŸ® GPU: {gpu.get('name', 'Unknown')}")
        print(f"   VRAM: {gpu.get('vram_gb', 0):.1f} GB")
        if gpu.get('compute_capability'):
            print(f"   Compute Capability: {gpu.get('compute_capability')}")
        if gpu.get('multi_processor_count'):
            print(f"   SM ìˆ˜: {gpu.get('multi_processor_count')}")
    else:
        print("\nâš ï¸  GPU: ê°ì§€ë˜ì§€ ì•ŠìŒ (CPU ëª¨ë“œ)")
    
    # ìµœì  ì„¤ì •
    if settings:
        print("\n" + "-" * 60)
        print("âš¡ ìë™ ìµœì í™” ì„¤ì •")
        print("-" * 60)
        print(f"   ë””ë°”ì´ìŠ¤: {settings.get('device', 'cpu').upper()}")
        print(f"   ë°°ì¹˜ í¬ê¸°: {settings.get('batch_size', 4)}")
        print(f"   ê°ì§€ ìŠ¤ì¼€ì¼: {settings.get('detect_scale', 0.5)}")
        print(f"   ê°ì§€ ê°„ê²©: {settings.get('detect_interval', 3)}í”„ë ˆì„ë§ˆë‹¤")
        print(f"   ì›Œì»¤ ìˆ˜: {settings.get('num_workers', 2)}")
        print(f"   í í¬ê¸°: {settings.get('queue_size', 64)}")
        print(f"   FP16 ì¶”ë¡ : {'âœ… í™œì„±í™”' if settings.get('use_fp16') else 'âŒ ë¹„í™œì„±í™”'}")
    
    print("=" * 60 + "\n")


def get_optimal_device():
    """ìµœì  ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
    import torch
    if torch.cuda.is_available():
        return 'cuda'
    elif torch.backends.mps.is_available() and platform.processor() == 'arm':
        return 'mps'
    return 'cpu'


def get_cuda_info():
    """CUDA GPU ìƒì„¸ ì •ë³´ ë°˜í™˜"""
    import torch
    if not torch.cuda.is_available():
        return None
    
    info = {
        'device_count': torch.cuda.device_count(),
        'current_device': torch.cuda.current_device(),
        'devices': []
    }
    
    for i in range(info['device_count']):
        props = torch.cuda.get_device_properties(i)
        device_info = {
            'id': i,
            'name': props.name,
            'total_memory_gb': props.total_memory / (1024**3),
            'compute_capability': f"{props.major}.{props.minor}",
            'multi_processor_count': props.multi_processor_count,
        }
        info['devices'].append(device_info)
    
    return info


def setup_cuda_optimization(device='cuda', gpu_id=0):
    """CUDA ìµœì í™” ì„¤ì •"""
    import torch
    
    if not torch.cuda.is_available():
        return False
    
    # íŠ¹ì • GPU ì„ íƒ
    if gpu_id >= 0 and gpu_id < torch.cuda.device_count():
        torch.cuda.set_device(gpu_id)
    
    # CUDA ìµœì í™” í”Œë˜ê·¸ ì„¤ì •
    torch.backends.cudnn.enabled = True
    torch.backends.cudnn.benchmark = True  # ì…ë ¥ í¬ê¸° ì¼ì • ì‹œ ìµœì  ì•Œê³ ë¦¬ì¦˜ ìë™ ì„ íƒ
    torch.backends.cuda.matmul.allow_tf32 = True  # TF32 ì—°ì‚° í—ˆìš© (Ampere+)
    torch.backends.cudnn.allow_tf32 = True
    
    # ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€
    if hasattr(torch.cuda, 'memory'):
        torch.cuda.empty_cache()
    
    return True


def get_optimal_batch_size(device='cuda', frame_width=3840, frame_height=2160, detect_scale=0.5):
    """GPU ë©”ëª¨ë¦¬ ê¸°ë°˜ ìµœì  ë°°ì¹˜ í¬ê¸° ìë™ ê³„ì‚°"""
    import torch
    
    if device == 'cpu':
        return 2
    elif device == 'mps':
        return 4
    elif device == 'cuda' and torch.cuda.is_available():
        # GPU ë©”ëª¨ë¦¬ ê¸°ë°˜ ê³„ì‚°
        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        
        # ëŒ€ëµì  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì • (í”„ë ˆì„ë‹¹ ~200MB for 4K at 0.5 scale)
        scaled_width = int(frame_width * detect_scale)
        scaled_height = int(frame_height * detect_scale)
        frame_memory_mb = (scaled_width * scaled_height * 3 * 4) / (1024**2)  # float32
        
        # GPU ë©”ëª¨ë¦¬ì˜ 60% ì‚¬ìš©, ìµœì†Œ 1GB ì—¬ìœ 
        available_memory_mb = (gpu_memory_gb * 0.6 - 1) * 1024
        
        # YOLO ëª¨ë¸ ìì²´ ë©”ëª¨ë¦¬ (~500MB)
        model_memory_mb = 500
        available_memory_mb -= model_memory_mb
        
        # ë°°ì¹˜ë‹¹ ì¶”ê°€ ë©”ëª¨ë¦¬ (feature maps ë“±) ~3x frame memory
        batch_memory_mb = frame_memory_mb * 3
        
        optimal_batch = max(1, int(available_memory_mb / batch_memory_mb))
        optimal_batch = min(optimal_batch, 16)  # ìµœëŒ€ 16
        
        return optimal_batch
    
    return 4  # ê¸°ë³¸ê°’


def create_custom_tracker_config(tracker_type, track_buffer, match_thresh):
    """ì»¤ìŠ¤í…€ íŠ¸ë˜ì»¤ ì„¤ì • íŒŒì¼ ìƒì„±"""
    if tracker_type == "bytetrack":
        config = {
            'tracker_type': 'bytetrack',
            'track_high_thresh': 0.5,
            'track_low_thresh': 0.1,
            'new_track_thresh': 0.6,
            'track_buffer': track_buffer,
            'match_thresh': match_thresh,
            'fuse_score': True
        }
    else:  # botsort
        config = {
            'tracker_type': 'botsort',
            'track_high_thresh': 0.5,
            'track_low_thresh': 0.1,
            'new_track_thresh': 0.6,
            'track_buffer': track_buffer,
            'match_thresh': match_thresh,
            'proximity_thresh': 0.5,
            'appearance_thresh': 0.25,
            'with_reid': False,
            'gmc_method': 'sparseOptFlow',
            'fuse_score': True
        }

    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    temp_file = tempfile.NamedTemporaryFile(
        mode='w', suffix='.yaml', delete=False, prefix=f'{tracker_type}_custom_'
    )
    yaml.dump(config, temp_file, default_flow_style=False)
    temp_file.close()
    return temp_file.name


def download_opencv_face_model():
    """OpenCV DNN ì–¼êµ´ ê°ì§€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    MODELS_DIR.mkdir(parents=True, exist_ok=True)

    proto_path = MODELS_DIR / "deploy.prototxt"
    model_path = MODELS_DIR / "res10_300x300_ssd_iter_140000.caffemodel"

    if proto_path.exists() and model_path.exists():
        return proto_path, model_path

    print("OpenCV ì–¼êµ´ ê°ì§€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")

    try:
        if not proto_path.exists():
            urllib.request.urlretrieve(FACE_PROTO_URL, proto_path)
        if not model_path.exists():
            urllib.request.urlretrieve(FACE_MODEL_URL, model_path)
        print("ì–¼êµ´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        return proto_path, model_path
    except Exception as e:
        print(f"ì–¼êµ´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None


def check_opencv_cuda_support():
    """OpenCV CUDA ì§€ì› ì—¬ë¶€ í™•ì¸"""
    try:
        # OpenCVê°€ CUDAë¡œ ë¹Œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        build_info = cv2.getBuildInformation()
        cuda_support = 'CUDA:' in build_info and 'YES' in build_info.split('CUDA:')[1].split('\n')[0]
        cudnn_support = 'cuDNN:' in build_info and 'YES' in build_info.split('cuDNN:')[1].split('\n')[0]
        return cuda_support and cudnn_support
    except Exception:
        return False


class FaceDetectorDNN:
    """OpenCV DNN ê¸°ë°˜ ì–¼êµ´ ê°ì§€ (CUDA ê°€ì† ì§€ì›)"""

    def __init__(self, confidence=0.5, input_size=300, use_cuda=True):
        proto_path, model_path = download_opencv_face_model()
        self.use_cuda = False  # ì‹¤ì œ CUDA ì‚¬ìš© ì—¬ë¶€

        if proto_path and model_path:
            self.net = cv2.dnn.readNetFromCaffe(str(proto_path), str(model_path))

            # CUDA ë°±ì—”ë“œ ì‹œë„ (ê°€ëŠ¥í•œ ê²½ìš°)
            if use_cuda and check_opencv_cuda_support():
                try:
                    self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
                    self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)
                    self.use_cuda = True
                    print("   âœ… OpenCV DNN CUDA ê°€ì† í™œì„±í™”")
                except Exception as e:
                    print(f"   âš ï¸ OpenCV CUDA ë°±ì—”ë“œ ì‹¤íŒ¨, CPUë¡œ í´ë°±: {e}")
                    self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
                    self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            else:
                # CPU ë°±ì—”ë“œ ì‚¬ìš©
                self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
                self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
                if use_cuda:
                    print("   âš ï¸ OpenCV CUDA ë¯¸ì§€ì›, CPU ë°±ì—”ë“œ ì‚¬ìš©")

            self.enabled = True
        else:
            self.net = None
            self.enabled = False
        self.confidence = confidence
        self.input_size = input_size

    def detect(self, frame, scale_factor=1.0):
        """ì–¼êµ´ ê°ì§€ - [(x1,y1,x2,y2), ...] ë°˜í™˜"""
        if not self.enabled:
            return []

        h, w = frame.shape[:2]

        # ë‹¤ìš´ìŠ¤ì¼€ì¼ëœ ì´ë¯¸ì§€ë¡œ ê°ì§€
        if scale_factor < 1.0:
            small_frame = cv2.resize(frame, (int(w * scale_factor), int(h * scale_factor)))
            detect_h, detect_w = small_frame.shape[:2]
        else:
            small_frame = frame
            detect_h, detect_w = h, w

        blob = cv2.dnn.blobFromImage(
            cv2.resize(small_frame, (self.input_size, self.input_size)),
            1.0, (self.input_size, self.input_size),
            (104.0, 177.0, 123.0)
        )

        self.net.setInput(blob)
        detections = self.net.forward()

        faces = []
        for i in range(detections.shape[2]):
            conf = detections[0, 0, i, 2]
            if conf > self.confidence:
                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                x1, y1, x2, y2 = box.astype(int)
                faces.append((x1, y1, x2, y2, conf))

        return faces


class FrameReader(Thread):
    """ë¹„ë™ê¸° í”„ë ˆì„ ì½ê¸° ìŠ¤ë ˆë“œ"""

    def __init__(self, cap, queue, start_frame, end_frame, queue_size=128):
        super().__init__(daemon=True)
        self.cap = cap
        self.queue = queue
        self.start_frame = start_frame
        self.end_frame = end_frame
        self.stopped = Event()

    def run(self):
        frame_idx = self.start_frame
        while not self.stopped.is_set() and frame_idx < self.end_frame:
            if self.queue.full():
                time.sleep(0.001)
                continue
            ret, frame = self.cap.read()
            if not ret:
                break
            self.queue.put((frame_idx, frame))
            frame_idx += 1
        self.queue.put(None)  # ì¢…ë£Œ ì‹ í˜¸

    def stop(self):
        self.stopped.set()


class FrameWriter(Thread):
    """ë¹„ë™ê¸° í”„ë ˆì„ ì“°ê¸° ìŠ¤ë ˆë“œ"""

    def __init__(self, out, queue):
        super().__init__(daemon=True)
        self.out = out
        self.queue = queue
        self.stopped = Event()
        self.frames_written = 0

    def run(self):
        pending = {}
        next_frame = 0

        while not self.stopped.is_set():
            try:
                item = self.queue.get(timeout=0.1)
            except Empty:
                continue

            if item is None:
                # ë‚¨ì€ í”„ë ˆì„ ëª¨ë‘ ì“°ê¸°
                while next_frame in pending:
                    self.out.write(pending.pop(next_frame))
                    self.frames_written += 1
                    next_frame += 1
                break

            frame_idx, frame = item
            pending[frame_idx] = frame

            # ìˆœì„œëŒ€ë¡œ ì“°ê¸°
            while next_frame in pending:
                self.out.write(pending.pop(next_frame))
                self.frames_written += 1
                next_frame += 1

    def stop(self):
        self.stopped.set()


def get_plate_region(vehicle_box, expand_ratio=0.3):
    """ì°¨ëŸ‰ bboxì—ì„œ ë²ˆí˜¸íŒ ì˜ì—­ ì¶”ì •"""
    x1, y1, x2, y2 = vehicle_box[:4]
    height = y2 - y1
    width = x2 - x1

    plate_height = height * 0.18
    plate_width = width * 0.45

    center_x = (x1 + x2) / 2

    plate_x1 = center_x - plate_width / 2
    plate_x2 = center_x + plate_width / 2
    plate_y1 = y2 - height * 0.35
    plate_y2 = y2 - height * 0.08

    expand_w = (plate_x2 - plate_x1) * expand_ratio
    expand_h = (plate_y2 - plate_y1) * expand_ratio

    plate_x1 = max(0, plate_x1 - expand_w)
    plate_x2 = plate_x2 + expand_w
    plate_y1 = max(0, plate_y1 - expand_h)
    plate_y2 = plate_y2 + expand_h

    return int(plate_x1), int(plate_y1), int(plate_x2), int(plate_y2)


def apply_blur(frame, x1, y1, x2, y2, blur_strength=51):
    """ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©"""
    h, w = frame.shape[:2]

    x1 = max(0, min(int(x1), w))
    x2 = max(0, min(int(x2), w))
    y1 = max(0, min(int(y1), h))
    y2 = max(0, min(int(y2), h))

    if x2 <= x1 or y2 <= y1:
        return frame

    blur_strength = blur_strength if blur_strength % 2 == 1 else blur_strength + 1

    roi = frame[y1:y2, x1:x2]
    blurred = cv2.GaussianBlur(roi, (blur_strength, blur_strength), 0)
    frame[y1:y2, x1:x2] = blurred

    return frame


def apply_mosaic(frame, x1, y1, x2, y2, block_size=15):
    """ëª¨ìì´í¬ ì ìš©"""
    h, w = frame.shape[:2]

    x1 = max(0, min(int(x1), w))
    x2 = max(0, min(int(x2), w))
    y1 = max(0, min(int(y1), h))
    y2 = max(0, min(int(y2), h))

    if x2 <= x1 or y2 <= y1:
        return frame

    roi = frame[y1:y2, x1:x2]
    roi_h, roi_w = roi.shape[:2]

    if roi_h < block_size or roi_w < block_size:
        return frame

    small = cv2.resize(roi, (max(1, roi_w // block_size), max(1, roi_h // block_size)),
                       interpolation=cv2.INTER_LINEAR)
    mosaic = cv2.resize(small, (roi_w, roi_h), interpolation=cv2.INTER_NEAREST)
    frame[y1:y2, x1:x2] = mosaic

    return frame


def expand_box(box, ratio, frame_shape):
    """ë°•ìŠ¤ í™•ì¥"""
    x1, y1, x2, y2 = box[:4]
    h, w = frame_shape[:2]

    box_w = x2 - x1
    box_h = y2 - y1

    expand_w = box_w * ratio
    expand_h = box_h * ratio

    x1 = max(0, x1 - expand_w)
    x2 = min(w, x2 + expand_w)
    y1 = max(0, y1 - expand_h)
    y2 = min(h, y2 + expand_h)

    return int(x1), int(y1), int(x2), int(y2)


def interpolate_box(box1, box2, alpha):
    """ë‘ ë°•ìŠ¤ ì‚¬ì´ ì„ í˜• ë³´ê°„"""
    if box1 is None:
        return box2
    if box2 is None:
        return box1
    return tuple(int(b1 * (1 - alpha) + b2 * alpha) for b1, b2 in zip(box1[:4], box2[:4]))


class TrackingInterpolator:
    """íŠ¸ë˜í‚¹ ê²°ê³¼ ë³´ê°„ ê´€ë¦¬"""

    def __init__(self, max_age=30):
        self.tracks = {}  # track_id -> {'boxes': deque, 'last_seen': frame_idx}
        self.max_age = max_age

    def update(self, frame_idx, detections):
        """ìƒˆ ê°ì§€ ê²°ê³¼ë¡œ ì—…ë°ì´íŠ¸"""
        seen_ids = set()

        for det in detections:
            track_id = det.get('track_id')
            if track_id is None:
                continue

            seen_ids.add(track_id)
            box = det['box']

            if track_id not in self.tracks:
                self.tracks[track_id] = {
                    'boxes': deque(maxlen=10),
                    'last_seen': frame_idx,
                    'type': det.get('type', 'unknown')
                }

            self.tracks[track_id]['boxes'].append((frame_idx, box))
            self.tracks[track_id]['last_seen'] = frame_idx

        # ì˜¤ë˜ëœ íŠ¸ë™ ì œê±°
        expired = [tid for tid, t in self.tracks.items()
                   if frame_idx - t['last_seen'] > self.max_age]
        for tid in expired:
            del self.tracks[tid]

    def get_interpolated(self, frame_idx):
        """í˜„ì¬ í”„ë ˆì„ì— ëŒ€í•œ ë³´ê°„ëœ ë°•ìŠ¤ë“¤ ë°˜í™˜"""
        results = []

        for track_id, track in self.tracks.items():
            boxes = track['boxes']
            if len(boxes) == 0:
                continue

            # ê°€ì¥ ìµœê·¼ ë°•ìŠ¤ ì°¾ê¸°
            last_frame, last_box = boxes[-1]

            if frame_idx == last_frame:
                # ì •í™•íˆ ì¼ì¹˜
                results.append({
                    'track_id': track_id,
                    'box': last_box,
                    'type': track['type'],
                    'interpolated': False
                })
            elif frame_idx > last_frame and frame_idx - last_frame <= self.max_age:
                # ë³´ê°„ (ë§ˆì§€ë§‰ ë°•ìŠ¤ ì‚¬ìš©, ë˜ëŠ” ì†ë„ ê¸°ë°˜ ì˜ˆì¸¡)
                if len(boxes) >= 2:
                    prev_frame, prev_box = boxes[-2]
                    # ì†ë„ ê³„ì‚°
                    dt = last_frame - prev_frame
                    if dt > 0:
                        velocity = tuple((b2 - b1) / dt for b1, b2 in zip(prev_box, last_box))
                        frames_ahead = frame_idx - last_frame
                        predicted_box = tuple(int(b + v * frames_ahead) for b, v in zip(last_box, velocity))
                        results.append({
                            'track_id': track_id,
                            'box': predicted_box,
                            'type': track['type'],
                            'interpolated': True
                        })
                else:
                    results.append({
                        'track_id': track_id,
                        'box': last_box,
                        'type': track['type'],
                        'interpolated': True
                    })

        return results


class VideoMaskerOptimized:
    """ìµœì í™”ëœ ë¹„ë””ì˜¤ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(
        self,
        mask_faces: bool = True,
        mask_plates: bool = True,
        mask_type: str = "blur",
        blur_strength: int = 51,
        mosaic_size: int = 15,
        face_confidence: float = 0.4,
        vehicle_confidence: float = 0.3,
        face_expand: float = 0.2,
        plate_expand: float = 0.3,
        # ìµœì í™” íŒŒë¼ë¯¸í„°
        device: str = "auto",
        detect_interval: int = -1,  # Ní”„ë ˆì„ë§ˆë‹¤ ê°ì§€ (-1 = ìë™)
        detect_scale: float = -1,  # ê°ì§€ìš© ë‹¤ìš´ìŠ¤ì¼€ì¼ (-1 = ìë™)
        batch_size: int = -1,  # ë°°ì¹˜ ì¶”ë¡  í¬ê¸° (-1 = ìë™)
        # NVIDIA GPU ìµœì í™” íŒŒë¼ë¯¸í„°
        gpu_id: int = 0,  # ì‚¬ìš©í•  GPU ID
        use_fp16: bool = None,  # FP16 ë°˜ì •ë°€ë„ ì¶”ë¡  (None = ìë™)
        use_tensorrt: bool = False,  # TensorRT ê°€ì† (ì‚¬ì „ ë³€í™˜ í•„ìš”)
        # ì‹œìŠ¤í…œ ìµœì í™”
        auto_optimize: bool = True,  # ì‹œìŠ¤í…œ ì‚¬ì–‘ ê¸°ë°˜ ìë™ ìµœì í™”
        queue_size: int = -1,  # í”„ë ˆì„ í í¬ê¸° (-1 = ìë™)
        # íŠ¸ë˜í‚¹ íŒŒë¼ë¯¸í„°
        tracker: str = "bytetrack",
        track_buffer: int = 30,
        match_thresh: float = 0.8,
        iou_thresh: float = 0.5,
    ):
        self.mask_faces = mask_faces
        self.mask_plates = mask_plates
        self.mask_type = mask_type
        self.blur_strength = blur_strength
        self.mosaic_size = mosaic_size
        self.face_confidence = face_confidence
        self.vehicle_confidence = vehicle_confidence
        self.face_expand = face_expand
        self.plate_expand = plate_expand
        
        # ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ ë° ìë™ ìµœì í™”
        self.system_info = None
        self.optimal_settings = None
        
        if auto_optimize:
            self.system_info = get_system_info()
            self.optimal_settings = get_optimal_settings(self.system_info)
            print_system_info(self.system_info, self.optimal_settings)
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì • (ìë™ ë˜ëŠ” ìˆ˜ë™)
        if device == "auto":
            self.device = self.optimal_settings['device'] if self.optimal_settings else get_optimal_device()
        else:
            self.device = device

        # ìµœì í™” ì„¤ì • (ìë™ ë˜ëŠ” ìˆ˜ë™)
        if self.optimal_settings:
            self.detect_interval = detect_interval if detect_interval > 0 else self.optimal_settings['detect_interval']
            self.detect_scale = detect_scale if detect_scale > 0 else self.optimal_settings['detect_scale']
            self.batch_size = batch_size if batch_size > 0 else self.optimal_settings['batch_size']
            self.queue_size = queue_size if queue_size > 0 else self.optimal_settings['queue_size']
            self.use_fp16 = use_fp16 if use_fp16 is not None else self.optimal_settings['use_fp16']
            self.num_workers = self.optimal_settings['num_workers']
        else:
            self.detect_interval = detect_interval if detect_interval > 0 else 3
            self.detect_scale = detect_scale if detect_scale > 0 else 0.5
            self.batch_size = batch_size if batch_size > 0 else 4
            self.queue_size = queue_size if queue_size > 0 else 128
            self.use_fp16 = use_fp16 if use_fp16 is not None else False
            self.num_workers = 2
        
        self.tracker_type = tracker
        self.track_buffer = track_buffer
        self.match_thresh = match_thresh
        self.iou_thresh = iou_thresh
        
        # NVIDIA GPU ìµœì í™” ì„¤ì •
        self.gpu_id = gpu_id
        self.use_tensorrt = use_tensorrt
        
        # CUDA ìµœì í™” ì ìš©
        if self.device == 'cuda':
            setup_cuda_optimization(self.device, gpu_id)
            cuda_info = get_cuda_info()
            if cuda_info and not auto_optimize:  # ìë™ ìµœì í™” ì‹œ ì´ë¯¸ ì¶œë ¥ë¨
                gpu = cuda_info['devices'][gpu_id]
                print(f"ğŸ® NVIDIA GPU: {gpu['name']} ({gpu['total_memory_gb']:.1f}GB)")
                print(f"   Compute Capability: {gpu['compute_capability']}")
            if self.use_fp16:
                print(f"   âš¡ FP16 ë°˜ì •ë°€ë„ ì¶”ë¡  í™œì„±í™”")
            if use_tensorrt:
                print(f"   ğŸš€ TensorRT ê°€ì† í™œì„±í™”")
        elif not auto_optimize:
            print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")

        # ì»¤ìŠ¤í…€ íŠ¸ë˜ì»¤ ì„¤ì • íŒŒì¼ ìƒì„±
        self.tracker_config_path = create_custom_tracker_config(
            tracker, track_buffer, match_thresh
        )
        print(f"íŠ¸ë˜ì»¤ ì„¤ì •: {tracker} (buffer={track_buffer}, match_thresh={match_thresh})")

        # ëª¨ë¸ ë¡œë“œ
        self.face_detector = None
        self.vehicle_model = None
        self.yolo_half = False  # ê¸°ë³¸ê°’

        if mask_faces:
            use_dnn_cuda = (self.device == 'cuda')
            print(f"ì–¼êµ´ ê°ì§€ ëª¨ë¸ ë¡œë”© (OpenCV DNN, CUDA={'ì‹œë„' if use_dnn_cuda else 'ë¯¸ì‚¬ìš©'})...")
            self.face_detector = FaceDetectorDNN(confidence=face_confidence, use_cuda=use_dnn_cuda)
            if not self.face_detector.enabled:
                print("ê²½ê³ : ì–¼êµ´ ê°ì§€ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

        if mask_plates:
            print(f"ì°¨ëŸ‰ ê°ì§€ ëª¨ë¸ ë¡œë”© (YOLOv8, device={self.device})...")
            
            # TensorRT ì—”ì§„ ì‚¬ìš© (ì‚¬ì „ ë³€í™˜ í•„ìš”)
            if use_tensorrt and self.device == 'cuda':
                tensorrt_model_path = Path("yolov8n.engine")
                if tensorrt_model_path.exists():
                    print("   TensorRT ì—”ì§„ ë¡œë”©...")
                    self.vehicle_model = YOLO(str(tensorrt_model_path))
                else:
                    print("   âš ï¸ TensorRT ì—”ì§„ ì—†ìŒ. ìµœì´ˆ 1íšŒ ë³€í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    print("   ë³€í™˜ ëª…ë ¹: yolo export model=yolov8n.pt format=engine half=True")
                    self.vehicle_model = YOLO("yolov8n.pt")
            else:
                self.vehicle_model = YOLO("yolov8n.pt")
            
            # GPU ê°€ì† í™œì„±í™”
            if self.device != 'cpu':
                self.vehicle_model.to(self.device)
                
            # FP16 ì„¤ì • ì €ì¥ (ì¶”ë¡  ì‹œ ì‚¬ìš©)
            self.yolo_half = self.use_fp16 and self.device == 'cuda'

        # COCO í´ë˜ìŠ¤
        self.VEHICLE_CLASSES = [2, 3, 5, 7]  # car, motorcycle, bus, truck

        # íŠ¸ë˜í‚¹ ë³´ê°„ê¸°
        self.face_interpolator = TrackingInterpolator(max_age=track_buffer)
        self.vehicle_interpolator = TrackingInterpolator(max_age=track_buffer)

        # ì–¼êµ´ íŠ¸ë˜í‚¹ìš© ê°„ë‹¨í•œ ID í• ë‹¹
        self.next_face_id = 0
        self.prev_faces = []

        # ì°¨ëŸ‰ íŠ¸ë˜í‚¹ìš© ID (track()ì´ IDë¥¼ ëª» ì¤„ ë•Œ ëŒ€ë¹„)
        self.next_vehicle_id = 10000

        # ë°°ì¹˜ ì²˜ë¦¬ìš© ë²„í¼
        self.frame_buffer = []
        self.frame_idx_buffer = []

    def _get_next_vehicle_id(self):
        """ì°¨ëŸ‰ìš© ê³ ìœ  ID ìƒì„±"""
        self.next_vehicle_id += 1
        return self.next_vehicle_id

    def apply_mask(self, frame, x1, y1, x2, y2):
        """ë§ˆìŠ¤í¬ ì ìš©"""
        if self.mask_type == "blur":
            return apply_blur(frame, x1, y1, x2, y2, self.blur_strength)
        else:
            return apply_mosaic(frame, x1, y1, x2, y2, self.mosaic_size)

    def match_faces_simple(self, prev_faces, curr_faces, iou_thresh=0.3):
        """ê°„ë‹¨í•œ IOU ê¸°ë°˜ ì–¼êµ´ ë§¤ì¹­"""
        def iou(box1, box2):
            x1 = max(box1[0], box2[0])
            y1 = max(box1[1], box2[1])
            x2 = min(box1[2], box2[2])
            y2 = min(box1[3], box2[3])

            inter = max(0, x2 - x1) * max(0, y2 - y1)
            area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
            area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
            union = area1 + area2 - inter

            return inter / union if union > 0 else 0

        matched = []
        used_prev = set()

        for curr in curr_faces:
            best_iou = 0
            best_prev = None
            best_idx = -1

            for idx, prev in enumerate(prev_faces):
                if idx in used_prev:
                    continue
                score = iou(curr[:4], prev['box'][:4])
                if score > best_iou and score > iou_thresh:
                    best_iou = score
                    best_prev = prev
                    best_idx = idx

            if best_prev:
                used_prev.add(best_idx)
                matched.append({
                    'box': curr[:4],
                    'conf': curr[4] if len(curr) > 4 else 1.0,
                    'track_id': best_prev['track_id'],
                    'type': 'face'
                })
            else:
                matched.append({
                    'box': curr[:4],
                    'conf': curr[4] if len(curr) > 4 else 1.0,
                    'track_id': self.next_face_id,
                    'type': 'face'
                })
                self.next_face_id += 1

        return matched

    def detect_all(self, frame, frame_idx):
        """ì–¼êµ´ê³¼ ì°¨ëŸ‰ ëª¨ë‘ ê°ì§€ (ìµœì í™”)"""
        detections = {'faces': [], 'vehicles': []}
        h, w = frame.shape[:2]

        # ê°ì§€ìš© ë‹¤ìš´ìŠ¤ì¼€ì¼
        if self.detect_scale < 1.0:
            detect_frame = cv2.resize(
                frame,
                (int(w * self.detect_scale), int(h * self.detect_scale))
            )
            scale_x = w / detect_frame.shape[1]
            scale_y = h / detect_frame.shape[0]
        else:
            detect_frame = frame
            scale_x = scale_y = 1.0

        # ì–¼êµ´ ê°ì§€
        if self.mask_faces and self.face_detector and self.face_detector.enabled:
            faces = self.face_detector.detect(detect_frame)
            # ì›ë³¸ í•´ìƒë„ë¡œ ìŠ¤ì¼€ì¼ ë³µì›
            scaled_faces = []
            for face in faces:
                x1, y1, x2, y2 = face[:4]
                conf = face[4] if len(face) > 4 else 1.0
                scaled_faces.append((
                    int(x1 * scale_x), int(y1 * scale_y),
                    int(x2 * scale_x), int(y2 * scale_y),
                    conf
                ))

            # ê°„ë‹¨í•œ íŠ¸ë˜í‚¹ ë§¤ì¹­
            matched_faces = self.match_faces_simple(self.prev_faces, scaled_faces)
            detections['faces'] = matched_faces
            self.prev_faces = matched_faces

        # ì°¨ëŸ‰ ê°ì§€ (YOLO + ByteTrack) - device ëª…ì‹œ ë° ì»¤ìŠ¤í…€ íŠ¸ë˜ì»¤ ì‚¬ìš©
        if self.mask_plates and self.vehicle_model:
            results = self.vehicle_model.track(
                detect_frame,
                persist=True,
                conf=self.vehicle_confidence,
                iou=self.iou_thresh,
                tracker=self.tracker_config_path,  # ì»¤ìŠ¤í…€ íŠ¸ë˜ì»¤ ì„¤ì • ì‚¬ìš©
                device=self.device,  # GPU ë””ë°”ì´ìŠ¤ ëª…ì‹œ
                half=self.yolo_half,  # FP16 ì¶”ë¡ 
                verbose=False
            )

            if results[0].boxes is not None:
                for box in results[0].boxes:
                    cls = int(box.cls[0])
                    if cls in self.VEHICLE_CLASSES:
                        xyxy = box.xyxy[0].cpu().numpy()
                        # ì›ë³¸ í•´ìƒë„ë¡œ ìŠ¤ì¼€ì¼ ë³µì›
                        x1, y1, x2, y2 = xyxy
                        x1, x2 = int(x1 * scale_x), int(x2 * scale_x)
                        y1, y2 = int(y1 * scale_y), int(y2 * scale_y)

                        track_id = int(box.id[0]) if box.id is not None else None

                        detections['vehicles'].append({
                            'box': (x1, y1, x2, y2),
                            'track_id': track_id,
                            'type': 'vehicle',
                            'class': cls
                        })

        return detections

    def detect_batch(self, frames, frame_indices):
        """ë°°ì¹˜ ì¶”ë¡  - ì—¬ëŸ¬ í”„ë ˆì„ì„ í•œ ë²ˆì— ì²˜ë¦¬"""
        if not frames:
            return []

        h, w = frames[0].shape[:2]
        batch_detections = []

        # ê°ì§€ìš© ë‹¤ìš´ìŠ¤ì¼€ì¼
        if self.detect_scale < 1.0:
            detect_frames = [
                cv2.resize(f, (int(w * self.detect_scale), int(h * self.detect_scale)))
                for f in frames
            ]
            scale_x = w / detect_frames[0].shape[1]
            scale_y = h / detect_frames[0].shape[0]
        else:
            detect_frames = frames
            scale_x = scale_y = 1.0

        # ë¨¼ì € ë¹ˆ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        for _ in detect_frames:
            batch_detections.append({'faces': [], 'vehicles': []})

        # ì°¨ëŸ‰ ë°°ì¹˜ ê°ì§€ (YOLO) - í”„ë ˆì„ë³„ track() ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
        if self.mask_plates and self.vehicle_model:
            for batch_idx, detect_frame in enumerate(detect_frames):
                # track() ì‚¬ìš©í•˜ì—¬ íŠ¸ë˜í‚¹ ID ìœ ì§€
                results = self.vehicle_model.track(
                    detect_frame,
                    persist=True,
                    conf=self.vehicle_confidence,
                    iou=self.iou_thresh,
                    tracker=self.tracker_config_path,
                    device=self.device,
                    half=self.yolo_half,  # FP16 ì¶”ë¡ 
                    verbose=False
                )

                if results[0].boxes is not None:
                    for box in results[0].boxes:
                        cls = int(box.cls[0])
                        if cls in self.VEHICLE_CLASSES:
                            xyxy = box.xyxy[0].cpu().numpy()
                            x1, y1, x2, y2 = xyxy
                            x1, x2 = int(x1 * scale_x), int(x2 * scale_x)
                            y1, y2 = int(y1 * scale_y), int(y2 * scale_y)

                            track_id = int(box.id[0]) if box.id is not None else self._get_next_vehicle_id()

                            batch_detections[batch_idx]['vehicles'].append({
                                'box': (x1, y1, x2, y2),
                                'track_id': track_id,
                                'type': 'vehicle',
                                'class': cls
                            })

        # ì–¼êµ´ ê°ì§€ (í”„ë ˆì„ë³„ ì²˜ë¦¬ - OpenCV DNNì€ ë°°ì¹˜ ë¯¸ì§€ì›)
        if self.mask_faces and self.face_detector and self.face_detector.enabled:
            for batch_idx, detect_frame in enumerate(detect_frames):
                faces = self.face_detector.detect(detect_frame)
                scaled_faces = []
                for face in faces:
                    x1, y1, x2, y2 = face[:4]
                    conf = face[4] if len(face) > 4 else 1.0
                    scaled_faces.append((
                        int(x1 * scale_x), int(y1 * scale_y),
                        int(x2 * scale_x), int(y2 * scale_y),
                        conf
                    ))

                matched_faces = self.match_faces_simple(self.prev_faces, scaled_faces)
                batch_detections[batch_idx]['faces'] = matched_faces
                self.prev_faces = matched_faces

        return batch_detections

    def process_frame(self, frame, frame_idx, force_detect=False):
        """ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ (ìµœì í™”)"""
        should_detect = force_detect or (frame_idx % self.detect_interval == 0)

        if should_detect:
            # ì‹¤ì œ ê°ì§€ ìˆ˜í–‰
            detections = self.detect_all(frame, frame_idx)

            # ë³´ê°„ê¸° ì—…ë°ì´íŠ¸
            self.face_interpolator.update(frame_idx, detections['faces'])
            self.vehicle_interpolator.update(frame_idx, detections['vehicles'])

        # ë³´ê°„ëœ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        faces = self.face_interpolator.get_interpolated(frame_idx)
        vehicles = self.vehicle_interpolator.get_interpolated(frame_idx)

        # ì–¼êµ´ ë§ˆìŠ¤í‚¹
        if self.mask_faces:
            for face in faces:
                box = expand_box(face['box'], self.face_expand, frame.shape)
                frame = self.apply_mask(frame, *box)

        # ë²ˆí˜¸íŒ ë§ˆìŠ¤í‚¹
        if self.mask_plates:
            for vehicle in vehicles:
                plate_box = get_plate_region(vehicle['box'], self.plate_expand)
                frame = self.apply_mask(frame, *plate_box)

        return frame, len(faces), len(vehicles)

    def process_frames_batch(self, frames, frame_indices):
        """ë°°ì¹˜ í”„ë ˆì„ ì²˜ë¦¬ - ê°ì§€ëŠ” ë°°ì¹˜ë¡œ, ë§ˆìŠ¤í‚¹ì€ ê°œë³„ë¡œ"""
        results = []

        # ê°ì§€ê°€ í•„ìš”í•œ í”„ë ˆì„ í•„í„°ë§
        detect_frames = []
        detect_indices = []
        for i, (frame, idx) in enumerate(zip(frames, frame_indices)):
            if idx % self.detect_interval == 0:
                detect_frames.append(frame)
                detect_indices.append((i, idx))

        # ë°°ì¹˜ ê°ì§€ ìˆ˜í–‰
        if detect_frames:
            batch_detections = self.detect_batch(detect_frames, [idx for _, idx in detect_indices])

            # ë³´ê°„ê¸° ì—…ë°ì´íŠ¸
            for (batch_idx, frame_idx), detections in zip(detect_indices, batch_detections):
                self.face_interpolator.update(frame_idx, detections['faces'])
                self.vehicle_interpolator.update(frame_idx, detections['vehicles'])

        # ê° í”„ë ˆì„ì— ë§ˆìŠ¤í‚¹ ì ìš©
        for frame, frame_idx in zip(frames, frame_indices):
            faces = self.face_interpolator.get_interpolated(frame_idx)
            vehicles = self.vehicle_interpolator.get_interpolated(frame_idx)

            # ì–¼êµ´ ë§ˆìŠ¤í‚¹
            if self.mask_faces:
                for face in faces:
                    box = expand_box(face['box'], self.face_expand, frame.shape)
                    frame = self.apply_mask(frame, *box)

            # ë²ˆí˜¸íŒ ë§ˆìŠ¤í‚¹
            if self.mask_plates:
                for vehicle in vehicles:
                    plate_box = get_plate_region(vehicle['box'], self.plate_expand)
                    frame = self.apply_mask(frame, *plate_box)

            results.append((frame, len(faces), len(vehicles)))

        return results

    def process_video(
        self,
        input_path: str,
        output_path: str = None,
        start_time: float = None,
        end_time: float = None,
        use_hevc: bool = False,
        log_file: str = None,
        verbose: bool = False,
        num_threads: int = 2,  # ì½ê¸°/ì“°ê¸° ìŠ¤ë ˆë“œ ìˆ˜
    ):
        """ë¹„ë””ì˜¤ ì „ì²´ ì²˜ë¦¬ (ë©€í‹°ìŠ¤ë ˆë”©)"""
        import subprocess
        import tempfile

        # ë¡œê±° ì„¤ì •
        if log_file is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            log_file = str(Path(input_path).parent / f"masking_{timestamp}.log")

        logger = setup_logger(log_file, verbose)
        logger.info("=" * 60)
        logger.info("ìµœì í™” ë§ˆìŠ¤í‚¹ v2.4 ì‹œì‘")
        logger.info("=" * 60)

        start_total_time = time.time()

        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            logger.error(f"ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
            raise ValueError(f"ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")

        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        # ì‹œì‘/ì¢…ë£Œ í”„ë ˆì„ ê³„ì‚°
        start_frame = int(start_time * fps) if start_time else 0
        end_frame = int(end_time * fps) if end_time else total_frames
        end_frame = min(end_frame, total_frames)
        process_frames = end_frame - start_frame

        logger.info(f"ì…ë ¥ íŒŒì¼: {input_path}")
        logger.info(f"í•´ìƒë„: {width}x{height}, FPS: {fps:.2f}")
        logger.info(f"ì „ì²´ í”„ë ˆì„: {total_frames} ({total_frames/fps/60:.1f}ë¶„)")
        logger.info(f"ë””ë°”ì´ìŠ¤: {self.device}")
        logger.info(f"ê°ì§€ ê°„ê²©: {self.detect_interval}í”„ë ˆì„ë§ˆë‹¤")
        logger.info(f"ê°ì§€ ìŠ¤ì¼€ì¼: {self.detect_scale}")
        logger.info(f"ë°°ì¹˜ í¬ê¸°: {self.batch_size}")
        logger.info(f"íŠ¸ë˜ì»¤: {self.tracker_type} (buffer={self.track_buffer}, match={self.match_thresh})")

        if start_time or end_time:
            start_min = start_frame / fps / 60
            end_min = end_frame / fps / 60
            logger.info(f"ì²˜ë¦¬ êµ¬ê°„: {start_min:.1f}ë¶„ ~ {end_min:.1f}ë¶„ ({process_frames} frames)")

        if output_path is None:
            input_stem = Path(input_path).stem
            suffix = f"_{int(start_time//60)}m-{int(end_time//60)}m" if start_time else ""
            output_path = str(Path(input_path).parent / f"{input_stem}{suffix}_masked.mp4")

        # ì‹œì‘ í”„ë ˆì„ìœ¼ë¡œ ì´ë™
        if start_frame > 0:
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            logger.debug(f"ì‹œì‘ í”„ë ˆì„ìœ¼ë¡œ ì´ë™: {start_frame}")

        # ì¶œë ¥ ì„¤ì •
        if use_hevc:
            temp_output = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(temp_output, fourcc, fps, (width, height))
            logger.info(f"ì¶œë ¥ íŒŒì¼: {output_path} (HEVC ì¸ì½”ë”© ì˜ˆì •)")
        else:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            logger.info(f"ì¶œë ¥ íŒŒì¼: {output_path}")

        logger.info(f"ì„¤ì •: ì–¼êµ´={'O' if self.mask_faces else 'X'}, "
                   f"ë²ˆí˜¸íŒ={'O' if self.mask_plates else 'X'}, "
                   f"ë°©ì‹={self.mask_type}")
        logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
        logger.info("-" * 60)

        # ë©€í‹°ìŠ¤ë ˆë”© ì„¤ì • (ì‹œìŠ¤í…œ RAM ê¸°ë°˜ í í¬ê¸°)
        read_queue = Queue(maxsize=self.queue_size)
        write_queue = Queue(maxsize=self.queue_size)

        reader = FrameReader(cap, read_queue, start_frame, end_frame)
        writer = FrameWriter(out, write_queue)

        reader.start()
        writer.start()

        processed_count = 0
        total_faces = 0
        total_vehicles = 0
        errors = []
        frame_times = []

        # ë°°ì¹˜ ë²„í¼
        batch_frames = []
        batch_indices = []

        try:
            while True:
                try:
                    item = read_queue.get(timeout=1.0)
                except Empty:
                    if not reader.is_alive():
                        break
                    continue

                if item is None:
                    # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
                    if batch_frames:
                        try:
                            batch_start = time.time()
                            results = self.process_frames_batch(batch_frames, batch_indices)
                            for (frame, n_faces, n_vehicles), idx in zip(results, batch_indices):
                                total_faces += n_faces
                                total_vehicles += n_vehicles
                                write_queue.put((idx, frame))
                            frame_times.append((time.time() - batch_start) / len(batch_frames))
                        except Exception as e:
                            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                            for frame, idx in zip(batch_frames, batch_indices):
                                write_queue.put((idx, frame))
                    break

                frame_idx, frame = item
                batch_frames.append(frame)
                batch_indices.append(processed_count)
                processed_count += 1

                # ë°°ì¹˜ê°€ ì°¼ìœ¼ë©´ ì²˜ë¦¬
                if len(batch_frames) >= self.batch_size:
                    try:
                        batch_start = time.time()
                        results = self.process_frames_batch(batch_frames, batch_indices)
                        for (frame, n_faces, n_vehicles), idx in zip(results, batch_indices):
                            total_faces += n_faces
                            total_vehicles += n_vehicles
                            write_queue.put((idx, frame))
                        frame_times.append((time.time() - batch_start) / len(batch_frames))
                    except Exception as e:
                        error_msg = f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
                        logger.error(error_msg)
                        errors.append(error_msg)
                        for frame, idx in zip(batch_frames, batch_indices):
                            write_queue.put((idx, frame))

                    batch_frames = []
                    batch_indices = []

                # ì§„í–‰ ìƒí™© ì¶œë ¥ (60í”„ë ˆì„ = ì•½ 1ì´ˆë§ˆë‹¤)
                if processed_count % 60 == 0:
                    progress = processed_count / process_frames * 100
                    elapsed = time.time() - start_total_time
                    avg_fps = processed_count / elapsed if elapsed > 0 else 0
                    eta_sec = (process_frames - processed_count) / avg_fps if avg_fps > 0 else 0
                    current_time_sec = processed_count / fps
                    logger.info(f"[{progress:5.1f}%] {processed_count:,}/{process_frames:,} frames | "
                               f"{current_time_sec/60:.1f}ë¶„ ì²˜ë¦¬ì™„ë£Œ | "
                               f"{avg_fps:.1f} fps | ë‚¨ì€ì‹œê°„: {eta_sec/60:.1f}ë¶„ | "
                               f"ì–¼êµ´: {total_faces}, ì°¨ëŸ‰: {total_vehicles}")

        except KeyboardInterrupt:
            logger.warning("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")

        finally:
            write_queue.put(None)
            reader.stop()
            writer.join(timeout=10)
            cap.release()
            out.release()

        # ë§ˆìŠ¤í‚¹ ì™„ë£Œ í†µê³„
        masking_time = time.time() - start_total_time
        logger.info("-" * 60)
        logger.info(f"ë§ˆìŠ¤í‚¹ ì™„ë£Œ!")
        logger.info(f"ì²˜ë¦¬ëœ í”„ë ˆì„: {processed_count}")
        logger.info(f"ê°ì§€ëœ ì–¼êµ´: {total_faces}, ì°¨ëŸ‰: {total_vehicles}")
        logger.info(f"ë§ˆìŠ¤í‚¹ ì†Œìš”ì‹œê°„: {masking_time/60:.1f}ë¶„")
        if frame_times:
            avg_fps = len(frame_times) / sum(frame_times)
            logger.info(f"í‰ê·  ì²˜ë¦¬ ì†ë„: {avg_fps:.1f} fps")
        if errors:
            logger.warning(f"ì˜¤ë¥˜ ë°œìƒ íšŸìˆ˜: {len(errors)}")

        # HEVC ì¸ì½”ë”© (NVENC í•˜ë“œì›¨ì–´ ê°€ì† ì§€ì›)
        if use_hevc:
            logger.info("\nHEVC ì¸ì½”ë”© ì‹œì‘...")
            hevc_start = time.time()

            # NVENC í•˜ë“œì›¨ì–´ ì¸ì½”ë” ìš°ì„  ì‹œë„ (RTX GPU)
            use_nvenc = self.device == 'cuda'
            if use_nvenc:
                ffmpeg_cmd = [
                    'ffmpeg', '-y',
                    '-i', temp_output,
                    '-c:v', 'hevc_nvenc',  # NVIDIA í•˜ë“œì›¨ì–´ ì¸ì½”ë”
                    '-preset', 'p4',  # ì†ë„/í’ˆì§ˆ ê· í˜• (p1=fastest, p7=best quality)
                    '-rc', 'vbr',  # Variable bitrate
                    '-cq', '23',  # í’ˆì§ˆ ìˆ˜ì¤€ (CRFì™€ ìœ ì‚¬)
                    '-b:v', '0',  # VBR ëª¨ë“œì—ì„œ í’ˆì§ˆ ê¸°ë°˜ ì¸ì½”ë”©
                    '-tag:v', 'hvc1',
                    '-an',
                    output_path
                ]
                logger.info("   NVENC í•˜ë“œì›¨ì–´ ì¸ì½”ë” ì‚¬ìš©")
            else:
                ffmpeg_cmd = [
                    'ffmpeg', '-y',
                    '-i', temp_output,
                    '-c:v', 'libx265',
                    '-preset', 'medium',
                    '-crf', '23',
                    '-tag:v', 'hvc1',
                    '-an',
                    output_path
                ]
                logger.info("   libx265 ì†Œí”„íŠ¸ì›¨ì–´ ì¸ì½”ë” ì‚¬ìš©")

            try:
                result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)
                hevc_time = time.time() - hevc_start

                # NVENC ì‹¤íŒ¨ ì‹œ libx265ë¡œ í´ë°±
                if result.returncode != 0 and use_nvenc:
                    logger.warning("   NVENC ì‹¤íŒ¨, libx265ë¡œ ì¬ì‹œë„...")
                    ffmpeg_cmd = [
                        'ffmpeg', '-y',
                        '-i', temp_output,
                        '-c:v', 'libx265',
                        '-preset', 'medium',
                        '-crf', '23',
                        '-tag:v', 'hvc1',
                        '-an',
                        output_path
                    ]
                    result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)
                    hevc_time = time.time() - hevc_start

                if result.returncode == 0:
                    logger.info(f"HEVC ì¸ì½”ë”© ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {hevc_time/60:.1f}ë¶„)")
                    os.unlink(temp_output)
                else:
                    logger.error(f"HEVC ì¸ì½”ë”© ì‹¤íŒ¨: {result.stderr}")
            except Exception as e:
                logger.error(f"ffmpeg ì‹¤í–‰ ì˜¤ë¥˜: {e}")

        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if self.device == 'cuda':
            import torch
            torch.cuda.empty_cache()
            logger.debug("GPU ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

        # ìµœì¢… ìš”ì•½
        total_time = time.time() - start_total_time
        logger.info("=" * 60)
        logger.info("ì‘ì—… ì™„ë£Œ ìš”ì•½")
        logger.info("=" * 60)
        logger.info(f"ì¶œë ¥ íŒŒì¼: {output_path}")
        logger.info(f"ì´ ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„")

        # ì„±ëŠ¥ ë¹„êµ
        video_duration = process_frames / fps
        speed_ratio = video_duration / total_time if total_time > 0 else 0
        logger.info(f"ì²˜ë¦¬ ì†ë„: {speed_ratio:.2f}x (ì‹¤ì‹œê°„ ëŒ€ë¹„)")
        
        # GPU ì‚¬ìš© ì •ë³´
        if self.device == 'cuda':
            import torch
            max_memory = torch.cuda.max_memory_allocated() / (1024**3)
            logger.info(f"GPU ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {max_memory:.2f}GB")

        return output_path


def parse_time(time_str):
    """ì‹œê°„ ë¬¸ìì—´ì„ ì´ˆë¡œ ë³€í™˜"""
    if time_str is None:
        return None
    if ':' in time_str:
        parts = time_str.split(':')
        if len(parts) == 2:
            return int(parts[0]) * 60 + float(parts[1])
        elif len(parts) == 3:
            return int(parts[0]) * 3600 + int(parts[1]) * 60 + float(parts[2])
    return float(time_str)


def main():
    parser = argparse.ArgumentParser(
        description="ìµœì í™”ëœ ì–¼êµ´/ë²ˆí˜¸íŒ ë§ˆìŠ¤í‚¹ v2.4 (ì‹œìŠ¤í…œ ìë™ ìµœì í™” + NVENC)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‚¬ìš© (ì‹œìŠ¤í…œ ì‚¬ì–‘ ìë™ ê°ì§€ ë° ìµœì í™”)
  python mask_video_optimized.py video.mp4

  # íŠ¹ì • êµ¬ê°„ ì²˜ë¦¬
  python mask_video_optimized.py video.mp4 --start 23:00 --end 28:00

  # ìˆ˜ë™ ì„¤ì • (ìë™ ìµœì í™” ë¹„í™œì„±í™”)
  python mask_video_optimized.py video.mp4 --no-auto --detect-interval 5 --batch-size 8

  # CPU ê°•ì œ ì‚¬ìš©
  python mask_video_optimized.py video.mp4 --device cpu

  # NVIDIA GPU + FP16 ê°•ì œ í™œì„±í™”
  python mask_video_optimized.py video.mp4 --fp16

  # NVIDIA GPU + TensorRT (ìµœê³  ì„±ëŠ¥, ì‚¬ì „ ë³€í™˜ í•„ìš”)
  python mask_video_optimized.py video.mp4 --tensorrt

  # TensorRT ì—”ì§„ ì‚¬ì „ ë³€í™˜
  yolo export model=yolov8n.pt format=engine half=True

  # HEVC ì¸ì½”ë”© (RTX GPUì—ì„œ NVENC í•˜ë“œì›¨ì–´ ì¸ì½”ë” ìë™ ì‚¬ìš©)
  python mask_video_optimized.py video.mp4 --hevc --verbose

RTX 4070 Super ìµœì  ì„¤ì • (12GB VRAM):
  - ë°°ì¹˜ í¬ê¸°: ~12-16
  - ê°ì§€ ê°„ê²©: 1 (ë§¤ í”„ë ˆì„)
  - FP16: ìë™ í™œì„±í™”
  - NVENC: HEVC ì¸ì½”ë”© ì‹œ ìë™ ì‚¬ìš©
        """
    )

    parser.add_argument("input", help="ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼")
    parser.add_argument("-o", "--output", help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--start", type=str, help="ì‹œì‘ ì‹œê°„ (ì˜ˆ: 23:00)")
    parser.add_argument("--end", type=str, help="ì¢…ë£Œ ì‹œê°„ (ì˜ˆ: 28:00)")
    parser.add_argument("--hevc", action="store_true", help="HEVC ì¸ì½”ë”© ì‚¬ìš©")

    # ë§ˆìŠ¤í‚¹ ì˜µì…˜
    parser.add_argument("--no-faces", action="store_true", help="ì–¼êµ´ ë§ˆìŠ¤í‚¹ ë¹„í™œì„±í™”")
    parser.add_argument("--no-plates", action="store_true", help="ë²ˆí˜¸íŒ ë§ˆìŠ¤í‚¹ ë¹„í™œì„±í™”")
    parser.add_argument("--mask-type", choices=["blur", "mosaic"], default="blur")
    parser.add_argument("--blur-strength", type=int, default=51)
    parser.add_argument("--mosaic-size", type=int, default=15)

    # ê°ì§€ íŒŒë¼ë¯¸í„°
    parser.add_argument("--face-conf", type=float, default=0.4, help="ì–¼êµ´ ê°ì§€ ì‹ ë¢°ë„")
    parser.add_argument("--vehicle-conf", type=float, default=0.3, help="ì°¨ëŸ‰ ê°ì§€ ì‹ ë¢°ë„")
    parser.add_argument("--face-expand", type=float, default=0.2, help="ì–¼êµ´ ì˜ì—­ í™•ì¥ ë¹„ìœ¨")
    parser.add_argument("--plate-expand", type=float, default=0.3, help="ë²ˆí˜¸íŒ ì˜ì—­ í™•ì¥ ë¹„ìœ¨")

    # ìµœì í™” íŒŒë¼ë¯¸í„°
    parser.add_argument("--device", type=str, default="auto",
                       choices=["auto", "cpu", "mps", "cuda"],
                       help="ì²˜ë¦¬ ë””ë°”ì´ìŠ¤ (ê¸°ë³¸: auto)")
    parser.add_argument("--detect-interval", type=int, default=-1,
                       help="ê°ì§€ ê°„ê²© (Ní”„ë ˆì„ë§ˆë‹¤ ê°ì§€, -1=ìë™)")
    parser.add_argument("--detect-scale", type=float, default=-1,
                       help="ê°ì§€ìš© ë‹¤ìš´ìŠ¤ì¼€ì¼ ë¹„ìœ¨ (-1=ìë™)")
    parser.add_argument("--batch-size", type=int, default=-1,
                       help="ë°°ì¹˜ ì¶”ë¡  í¬ê¸° (-1=ìë™)")
    
    # NVIDIA GPU ìµœì í™” íŒŒë¼ë¯¸í„°
    parser.add_argument("--gpu-id", type=int, default=0,
                       help="ì‚¬ìš©í•  GPU ID (ê¸°ë³¸: 0)")
    parser.add_argument("--fp16", action="store_true",
                       help="FP16 ë°˜ì •ë°€ë„ ì¶”ë¡  (NVIDIA GPUë§Œ, ì†ë„ í–¥ìƒ)")
    parser.add_argument("--tensorrt", action="store_true",
                       help="TensorRT ê°€ì† (ì‚¬ì „ ë³€í™˜ í•„ìš”)")
    
    # ì‹œìŠ¤í…œ ìë™ ìµœì í™”
    parser.add_argument("--no-auto", action="store_true",
                       help="ì‹œìŠ¤í…œ ìë™ ìµœì í™” ë¹„í™œì„±í™” (ìˆ˜ë™ ì„¤ì • ì‚¬ìš©)")
    parser.add_argument("--queue-size", type=int, default=-1,
                       help="í”„ë ˆì„ í í¬ê¸° (-1=ìë™, RAM ê¸°ë°˜)")

    # íŠ¸ë˜í‚¹ íŒŒë¼ë¯¸í„°
    parser.add_argument("--tracker", type=str, default="bytetrack",
                       choices=["bytetrack", "botsort"],
                       help="íŠ¸ë˜ì»¤ ì¢…ë¥˜ (ê¸°ë³¸: bytetrack)")
    parser.add_argument("--track-buffer", type=int, default=30,
                       help="íŠ¸ë˜í‚¹ ë²„í¼ í¬ê¸° (ê¸°ë³¸: 30)")
    parser.add_argument("--match-thresh", type=float, default=0.8,
                       help="íŠ¸ë˜í‚¹ ë§¤ì¹­ ì„ê³„ê°’ (ê¸°ë³¸: 0.8)")
    parser.add_argument("--iou-thresh", type=float, default=0.5,
                       help="IOU ì„ê³„ê°’ (ê¸°ë³¸: 0.5)")

    # ë¡œê¹…
    parser.add_argument("--log", type=str, help="ë¡œê·¸ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸")

    args = parser.parse_args()

    masker = VideoMaskerOptimized(
        mask_faces=not args.no_faces,
        mask_plates=not args.no_plates,
        mask_type=args.mask_type,
        blur_strength=args.blur_strength,
        mosaic_size=args.mosaic_size,
        face_confidence=args.face_conf,
        vehicle_confidence=args.vehicle_conf,
        face_expand=args.face_expand,
        plate_expand=args.plate_expand,
        device=args.device,
        detect_interval=args.detect_interval,
        detect_scale=args.detect_scale,
        batch_size=args.batch_size,
        gpu_id=args.gpu_id,
        use_fp16=args.fp16 if args.fp16 else None,
        use_tensorrt=args.tensorrt,
        auto_optimize=not args.no_auto,
        queue_size=args.queue_size,
        tracker=args.tracker,
        track_buffer=args.track_buffer,
        match_thresh=args.match_thresh,
        iou_thresh=args.iou_thresh,
    )

    masker.process_video(
        input_path=args.input,
        output_path=args.output,
        start_time=parse_time(args.start),
        end_time=parse_time(args.end),
        use_hevc=args.hevc,
        log_file=args.log,
        verbose=args.verbose,
    )


if __name__ == "__main__":
    main()
